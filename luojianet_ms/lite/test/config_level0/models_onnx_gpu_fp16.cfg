# [first column]:model_name, If you need input shape, please connect it through ';1;' after the model name, where '1' is the input num.
# [second column]:accuracy limit in arm64
Q888_face_recognition.onnx
Q_face_recognition.onnx
Q888_iris_detect.onnx
mtk_detect-deeper-halfdeeper-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-mbv1-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-deeper-halfdeeper-mbv1-lastearlySSD-shortcut-400-400_nopostprocess_simplified_onnx.onnx
mtk_detect-mbv2-shortcut-400-400-simplified.onnx
ml_face_3d.onnx
CloudBU_FSRCNN_RTC_8ch_3450_QP9.onnx;1;1,225,225,3 1.5
CloudBU_rfdn_rtc_x2_ver2_13.onnx;1;1,225,225,3 1.0
CloudBU_rfdn_rtc_x2_ver2_3450.onnx;1;1,225,225,3 108
ml_location_lane_counter0.onnx;1:input
mtk_face_features_v3.onnx 7
hdc_Face_Landmark5_MTI_Aesthetic.onnx
tinyyolov2-8.onnx;1;1,416,416,3 11
emotion-ferplus-8.onnx
#rcnn-ilsvrc13-9.onnx's precision deteriorates in P50(has nan value)
#rcnn-ilsvrc13-9.onnx
shufflenet-v2-10.onnx
squeezenet1.1-7.onnx
ml_table_detection_fp32_tmp.onnx
ml_table_segment.onnx
shufflenet-9.onnx
gts_version-RFB-320_simplified.onnx
mnist-8.onnx
ml_video_edit_judge.onnx 12
ml_video_edit_vignet.onnx
hdc_mobilenet_1w_class.onnx 22
ml_edu_kit_hand_detection.onnx
ml_edu_kit_hand_key_position.onnx
ml_2012_ocr_detection_tmp.onnx
ml_video_edit_enhance_update_tmp.onnx
bloom_hongmo_detection_tmp.onnx
ml_location_lane_counter.onnx 4
inception-v2-9.onnx
efficientnet-lite4-11.onnx;1:images:0
mobilenetv2-7.onnx;1:data 9
densenet-9.onnx;1:data_0
squeezenet1.0-9.onnx;1:data_0
residual_distill_cifar10_bs_1.onnx;1:actual_input
residual_distill_cifar10_bs_32.onnx;1:actual_input
residual_distill_bs_1.onnx;1:actual_input
#residual_distill_bs_32.onnx;1:actual_input 20
crnn_lite_lstm_v2.onnx;1:input;32,32,32,1
residual_distill_res34_cifar10_bs_1_update.onnx;1:actual_input
residual_distill_res50_cifar10_bs_1_update.onnx;1:actual_input
hdc_Image_Aesthetic_MTI_Aesthetic.onnx;1:input
hdc_resnet_1w_class.onnx;1:input.1
hdc_ocr_detect_tmp.onnx;1:actual_input_1
ml_facedetector.onnx;1:input
ml_ei_facedetection.onnx;1:input
mtk_emotions-d2012-75.onnx;1:input.1
mtk_detect_mbv1_640_480_nopostprocess_simplified_onnx.onnx;1:input;1,480,640,3
mtk_face_features_v2.onnx;1:input;1,256,192,3
simple_IPS_model_4D_input.onnx;1:pytorch_onnx
rpnt_pdr_conv2d_16_fixed_last.onnx;1:input
hdc_efficientnet_b3_1w_class.onnx;1:input.1
porseg_tmp.onnx;2:img,prev_mask
hiai_nlu_onnx_model_v1_0.onnx;3:input_ids,segment_ids,position_ids
ml_video_edit_makeup_mobilenetv203.onnx;1:input.1
Q888_CV_face_recognition_self.onnx;1:input
ml_video_edit_hair_dyeing_migrate_v2_fix.onnx;4
ml_motion_capture_spin_mobile_mv3_v3_57mm_sim.onnx;5:input,bbox,init_pose,init_shape,init_cam
ml_video_edit_dimming_tech_model_345000_color.onnx;2:input.18,1
Ireland_gaze_corrector.onnx;3:image,target_angle,strength 14
test_5d_relu_op.onnx;1:input
