# [first column]:model_name;input_num;input_shape;threads;extra_info. If there is no need to set these parameters, the
#                content after ";" can be omitted.
# [second column]:accuracy limit for float16 in arm64 device
ml_vision_guide_detection1.pb 0.5
ml_vision_guide_detection3.pb 0.5
ml_video_edit_generate_filter.pb 2
ml_ocr_jk.pb 0.8
# The accumulated error causes the threshold to be exceeded
ml_ocr_latin.pb 12
scan_hms_angle.pb 7
scan_hms_detect.pb 2.5
ml_face_openclose.pb;1;1,32,32,3 0.5
ml_object_detect.pb;1;1,288,288,3 2
# The inputs of two Q_crnn_screen_slim400w models are between 0-255, but their outputs have small values (e-7).
Q_crnn_screen_slim400w_more_20w.pb 72
Q_inception-249970-672-11-16.pb 6.5
hiai_ssd_mobilenetv2_object.pb 15
hiai_humanDetection.pb 3.5
hiai_PoseEstimation_Pcm.pb 0.5
# The last layer has a very small value, which leads to a large error
hiai_cn_recognize_modify_padv2.pb;1;1,32,512,1 37
hiai_model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3 17.1
# The output of mtk_model_ckpt.pb has small value
mtk_model_ckpt.pb 19.5
mtk_age_gender.pb 0.5
# The Difference of output node divided by 0 results in cumulative deviation
mtk_model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3 10
# Bccumulative error of conv_batchnorm_fused op
mtk_AADB_HADB_MBV2_model.pb;1;1,224,224,3 5.5
mtk_AADB_HADB_MBV3_model.pb;1;1,224,224,3 4
# The output of mtk_face_features_v1.pb has small value
mtk_face_features_v1.pb 26
model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3 10
hiai_AADB_HADB_MBV2_model.pb;1;1,224,224,3 6
hiai_frozen_inference_graph.pb 12
hiai_lm_inference_graph.pb 1.5
hiai_ghostnet.pb 0.9
hiai_face_model_npu.pb 0.5
hiai_cv_focusShootOCRModel_02.pb 12.5
hiai_label_and_video.pb;1;1,224,224,3 23
hiai_dress_detect.pb;1;1,960,960,3 1.5
hiai_iMaxDN_RGB.pb 0.5
hiai_iMaxSR_RGB.pb 5
hiai_ctpn_feature_map.pb 6.5
hiai_cpu_face_gazing.pb 0.5
hiai_cpu_face_emotion.pb 2.2
hiai_cv_poseEstimation.pb 103
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid.pb 1.5
# The input of Q_crnn_ori_75w_slim model is between 0-255, but its outputs has small values (e-6).
Q_crnn_ori_75w_slim_norm.pb 37
# The output of Q_crnn_ori_v2 model has small values (e-4).
Q_crnn_ori_v2_405001_notrans_nopre.pb 33
# The input of hiai_latin models are between 0-255
hiai_latin_ocr.pb 4
hiai_latin_ocr_1.pb 3.5
hiai_cpu_face_headpose.pb 4
# ml_noya_tts_melgan.pb  If the input range is adjusted to [- 1,1], the fp16 error can be reduced to 38.9512% 
ml_noya_tts_melgan.pb;1;16,16,80 70
bolt_segment.pb 2
siteAI_wireless_depress_w.pb;1;1,36 0.5
siteAI_wireless_restore_w.pb;1;1,36 0.5
siteAI_trans_nonlinear.pb;1;1,137 0.5
siteAI_trans_nonlinear40g.pb;1;1,271 0.7
siteAI_trans_nonlinear134g.pb;1;1,137 0.5
siteAI_trans_nonlinear134g_nrz.pb;1;1,182 0.6
ml_vision_guide_detection2.pb;1;1,320,320,1 1
# ml_tts_encoder.pb has a round op, which will cause round-off error when the decimal of input value is near 0.5
ml_tts_encoder.pb;4;1,44:1:1:1 9
# encoder_0111_control_flow.pb is same as ml_tts_encoder_control_flow.pb
#encoder_0111_control_flow.pb;4;1:1,44:1:1 10
ml_video_edit_video_segment_gauss_adaptis_part2.pb;2 16
ml_video_edit_img_segment_adaptise.pb;2 40
ml_video_edit_oneclick_adaptis.pb;3 6
#decoder_step_201217.pb is the same model as ml_tts_decoder.pb.
#decoder_step_201217.pb;5 187
#decoder_step_201217_modified.pb is the same model as ml_tts_decoder_control_flow.pb.
#decoder_step_201217_modified.pb;5 0.5
#encoder_0111.pb is the same model as ml_tts_encoder.pb.
#encoder_0111.pb;4;1:1,44:1:1
ml_female_model_step6_noiseout.pb;66 2
ml_male_model_step6_noiseout.pb;66 2.5
ml_tts_encoder_control_flow.pb;4;1,22:1:1:1;;input_dependent+need_loop 1.5
ml_tts_decoder_control_flow.pb;5;;;need_loop 1
ml_tts_decoder.pb;5 2.5
ml_tts_vocoder.pb;66 53
hiai_transformer_encoder.pb;15 4
decoder_step_nocumsum_v5.pb;13;1,512:1,512:1,512:1,512:1,512:1,127,320:1,1429,2:1,127:1:1,127:1,512:1,80:1,127 1.2
hiai_nlu_model_multi.pb;6;1,32:1,32:1,32:1,74:1,11:1,6
hiai_nlu_model_single.pb;3;1,32:1,32:1,32 4.4
fsr_270_mindspore.pb 6.0
fsr_360_mindspore.pb 6.5
fsr_720_mindspore.pb 2.0
hiai_asr_last_e1_cpu_fast_wavenet_batch1_frame1_one_cache.pb;2
tt_raw_h4800_mel80_ms_fe001_ex_20210506_joint_decoder.pb;14;4:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:1,640 0.5
ml_video_edit_shot_selection_opticalFlow.pb 9
hiai_asr_ctc.pb;2 5.5
g_00730000_female10_frames_tf1.pb;150:mel,resblocks_0_0,resblocks_0_1,up_0,resblocks_1_0,resblocks_1_1,up_1,resblocks_2_0,resblocks_2_1,up_2,resblocks_3_0,resblocks_3_1,up_3,resblocks_4_0,resblocks_4_1,up_4,residuals_0_0_0_0,residuals_0_0_0_1,residuals_0_0_1_0,residuals_0_0_1_1,residuals_0_0_2_0,residuals_0_0_2_1,residuals_0_0_3_0,residuals_0_0_3_1,residuals_0_2_2_0,residuals_0_2_2_1,residuals_0_2_3_0,residuals_0_2_3_1,residuals_1_0_0_0,residuals_1_0_0_1,residuals_1_0_1_0,residuals_1_0_1_1,residuals_1_0_2_0,residuals_1_0_2_1,residuals_1_0_3_0,residuals_1_0_3_1,residuals_1_1_0_0,residuals_1_1_0_1,residuals_1_1_1_0,residuals_1_1_1_1,residuals_1_1_2_0,residuals_1_1_2_1,residuals_1_1_3_0,residuals_1_1_3_1,1_2_0_0,residuals_1_2_0_1,residuals_1_2_1_0,residuals_1_2_1_1,residuals_1_2_2_0,residuals_1_2_2_1,residuals_1_2_3_0,residuals_1_2_3_1,residuals_2_1_0_0,residuals_2_1_0_1,residuals_2_1_1_0,residuals_2_1_1_1,residuals_2_1_2_0,residuals_2_1_2_1,residuals_2_1_3_0,residuals_2_1_3_1,2_2_0_0,residuals_2_2_0_1,residuals_2_2_1_0,residuals_2_2_1_1,residuals_2_2_2_0,residuals_2_2_2_1,residuals_2_2_3_0,residuals_2_2_3_1,residuals_3_0_0_0,residuals_3_0_0_1,residuals_3_0_1_0,residuals_3_0_1_1,residuals_3_0_2_0,residuals_3_0_2_1,residuals_3_0_3_0,residuals_3_0_3_1,residuals_3_2_2_0,residuals_3_2_2_1,residuals_3_2_3_0,residuals_3_2_3_1,residuals_4_0_0_0,residuals_4_0_0_1,residuals_4_0_1_0,residuals_4_0_1_1,residuals_4_0_2_0,residuals_4_0_2_1,residuals_4_0_3_0,residuals_4_0_3_1,residuals_4_2_2_0,residuals_4_2_2_1,residuals_4_2_3_0,residuals_4_2_3_1,cond_up_0,cond_up_1,cond_up_2,cond_up_3,mel_delay_1,mel_delay_2,mel_delay_3,mel_delay_4,res_output_0,res_output_1,res_output_2,conv_noise_stack,conv_pre_stack,conv_post_stack 4.2
scankit_angle.pb;1:normalized_input_image_tensor 0.7
scankit_detection_0.pb;1:normalized_input_image_tensor 2.5
# siteAI_aed.pb;1:x;32,384,16,1
# ml_audio_edit_ai_dubbing_qinqie32_encoder.pb;7:tones,alpha,input_length,phones,prosodies,seg_tags,languages;1,2:1:1:1,2:1,2:1,2:1,2
