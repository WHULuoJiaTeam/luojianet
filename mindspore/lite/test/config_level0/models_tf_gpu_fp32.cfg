# [first column]:model_name, If you need input shape, please connect it through ';1;' after the model name, where '1' is the input num.
# [second column]:accuracy limit in arm64
Q_hand_0812.pb
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid.pb
matmul.pb
inception_v3.pb;1;1,299,299,3
mobilenet_v1_0.25_128_frozen.pb;1;1,128,128,3
mobilenet_v2_1.0_224_frozen.pb;1;1,224,224,3
ml_face_openclose.pb;1;1,32,32,3
hiai_AADB_HADB_MBV2_model.pb;1;1,224,224,3
hiai_model_0909_kd_rot_ps_softmax.pb;1;1,224,224,3
model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3
mtk_AADB_HADB_MBV2_model.pb;1;1,224,224,3
mtk_AADB_HADB_MBV3_model.pb;1;1,224,224,3
mtk_model_face_dress.pb;1;1,128,128,3
hiai_model_normalize_object_scene_ps_20200519.pb;1;1,224,224,3
hiai_label_and_video.pb;1;1,224,224,3
mtk_age_gender.pb
mtk_model_ckpt.pb
Q_inception-249970-672-11-16.pb
Q_crnn_screen_slim400w_more_20w.pb
hiai_ssd_mobilenetv2_object.pb
hiai_humanDetection.pb
mtk_face_features_v1.pb
Q_crnn_ori_75w_slim_norm.pb
Q_crnn_ori_v2_405001_notrans_nopre.pb
bolt_segment.pb
hiai_cpu_face_emotion.pb
hiai_cpu_face_gazing.pb
hiai_cpu_face_headpose.pb
hiai_ctpn_feature_map.pb
hiai_cv_focusShootOCRModel_02.pb
hiai_cv_focusShootOCRModel_08.pb
hiai_cv_poseEstimation.pb
hiai_detectmodel_06_23_960_480_1180700.pb
hiai_face_model_npu.pb
hiai_iMaxDN_RGB.pb
hiai_iMaxSR_RGB.pb
hiai_lm_inference_graph.pb
hiai_PoseEstimation_Pcm.pb
hiai_asr_last_e1_cpu_fast_wavenet_batch1_frame1_one_cache.pb;2
Q888_CV_model_face_emo_dress_mv3.pb;1:img
Q888_CV_model_face_dress_mv3y.pb;1:input;1,112,112,3
unet_model_reconstruct.pb;1:content;1,256,256,3
ml_video_edit_generate_filter.pb;1:lowres_input
inception_resnet_v2.pb;1:input;1,299,299,3
inception_v4.pb;1:input;1,299,299,3
mnasnet_1.0_224.pb;1:input
mnasnet_1.3_224.pb;1:input
nasnet_large.pb;1:input;1,331,331,3
nasnet_mobile.pb;1:input;1,224,224,3
ml_ei_headpose.pb;1:input_1;1,64,64,3
ml_ocr_jk.pb;1:input_0
ml_video_edit_enhance.pb;1:lowres_input
scan_hms_angle.pb;1:normalized_input_image_tensor
scan_hms_detect.pb;1:normalized_input_image_tensor
hiai_cn_recognize_modify_padv2.pb;1:input_0;1,32,512,1
hiai_dress_detect.pb;1:data;1,960,960,3
hiai_ghostnet.pb;1:input
hiai_latin_ocr.pb;1:input_0
hiai_latin_ocr_1.pb;1:input_0
mtk_model_normalize_object_scene_ps_20200519.pb;1:input_0;1,224,224,3
ml_ocr_latin.pb;1:input_0
siteAI_wireless_depress_w.pb;1:x-input;1,36
siteAI_wireless_restore_w.pb;1:x-input;1,36
siteAI_trans_nonlinear.pb;1:features_placeholder;1,137
siteAI_trans_nonlinear40g.pb;1:features_placeholder;1,271
siteAI_trans_nonlinear134g.pb;1:features_placeholder;1,137
siteAI_trans_nonlinear134g_nrz.pb;1:features_placeholder;1,182
ml_video_edit_img_segment_adaptise.pb;2:backbone_features2,w
ml_video_edit_video_segment_gauss_adaptis_part2.pb;2:backbone_features2,w
# ml_video_edit_oneclick_adaptis.pb's precision deteriorates in P50
ml_video_edit_oneclick_adaptis.pb;3:image_input,point_input,coord_features 19
hiai_transformer_encoder.pb;15:buffer_in_0,buffer_in_1,buffer_in_2,buffer_in_3,buffer_in_4,buffer_in_5,buffer_in_6,buffer_in_7,buffer_in_8,buffer_in_9,buffer_in_10,buffer_in_11,buffer_in_12,buffer_in_13,encoder_in_deploy
fsr_270_mindspore.pb
fsr_360_mindspore.pb
fsr_720_mindspore.pb
ml_tts_decoder.pb;5:h_1,c_1,h_0,decoder_inputs_array,c_0
ml_video_edit_shot_selection_opticalFlow.pb;1:input
tensor_dot.pb;1:input;1,217
g_00730000_female10_frames_tf1.pb;150:mel,resblocks_0_0,resblocks_0_1,up_0,resblocks_1_0,resblocks_1_1,up_1,resblocks_2_0,resblocks_2_1,up_2,resblocks_3_0,resblocks_3_1,up_3,resblocks_4_0,resblocks_4_1,up_4,residuals_0_0_0_0,residuals_0_0_0_1,residuals_0_0_1_0,residuals_0_0_1_1,residuals_0_0_2_0,residuals_0_0_2_1,residuals_0_0_3_0,residuals_0_0_3_1,residuals_0_2_2_0,residuals_0_2_2_1,residuals_0_2_3_0,residuals_0_2_3_1,residuals_1_0_0_0,residuals_1_0_0_1,residuals_1_0_1_0,residuals_1_0_1_1,residuals_1_0_2_0,residuals_1_0_2_1,residuals_1_0_3_0,residuals_1_0_3_1,residuals_1_1_0_0,residuals_1_1_0_1,residuals_1_1_1_0,residuals_1_1_1_1,residuals_1_1_2_0,residuals_1_1_2_1,residuals_1_1_3_0,residuals_1_1_3_1,1_2_0_0,residuals_1_2_0_1,residuals_1_2_1_0,residuals_1_2_1_1,residuals_1_2_2_0,residuals_1_2_2_1,residuals_1_2_3_0,residuals_1_2_3_1,residuals_2_1_0_0,residuals_2_1_0_1,residuals_2_1_1_0,residuals_2_1_1_1,residuals_2_1_2_0,residuals_2_1_2_1,residuals_2_1_3_0,residuals_2_1_3_1,2_2_0_0,residuals_2_2_0_1,residuals_2_2_1_0,residuals_2_2_1_1,residuals_2_2_2_0,residuals_2_2_2_1,residuals_2_2_3_0,residuals_2_2_3_1,residuals_3_0_0_0,residuals_3_0_0_1,residuals_3_0_1_0,residuals_3_0_1_1,residuals_3_0_2_0,residuals_3_0_2_1,residuals_3_0_3_0,residuals_3_0_3_1,residuals_3_2_2_0,residuals_3_2_2_1,residuals_3_2_3_0,residuals_3_2_3_1,residuals_4_0_0_0,residuals_4_0_0_1,residuals_4_0_1_0,residuals_4_0_1_1,residuals_4_0_2_0,residuals_4_0_2_1,residuals_4_0_3_0,residuals_4_0_3_1,residuals_4_2_2_0,residuals_4_2_2_1,residuals_4_2_3_0,residuals_4_2_3_1,cond_up_0,cond_up_1,cond_up_2,cond_up_3,mel_delay_1,mel_delay_2,mel_delay_3,mel_delay_4,res_output_0,res_output_1,res_output_2,conv_noise_stack,conv_pre_stack,conv_post_stack
