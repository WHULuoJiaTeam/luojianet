hiai_model_0909_kd_rot_ps_softmax.tflite;1:input_0
hiai_chinese_english_recognize_model_float32.tflite;1:input_0
hiai_bigmodel_ghost_2_1_no_normalized_no_trans_tflite.tflite;1:input_0
hiai_bigmodel_ghost_5_1_no_normalized_no_trans_tflite.tflite;1:input_0
hiai_cn_recognize_modify_padv2.tflite;1:input_0
hiai_model_normalize_object_scene_ps_20200519.tflite;1:input_0
mtk_AADB_HADB_MBV2_model_fp32.tflite;1:input_0
mtk_AADB_HADB_MBV3_model_fp32.tflite;1:input_0
mobilenet_v1_0.25_128.tflite;1:input
mobilenet_v2_1.0_224.tflite;1:input
mtk_model_normalize_object_scene_ps_20200519_f32.tflite;1:input_0
mtk_model_ckpt.tflite;1:input
mtk_age_gender.tflite;1:img
mtk_model_face_dress.tflite;1:input
mtk_face_features_v1.tflite;1:input
densenet.tflite;1:Placeholder
squeezenet.tflite;1:Placeholder
resnet_v2_101_299.tflite;1:input
mnasnet_1.3_224.tflite;1:input
inception_v3.tflite;1:input
deeplabv3_257_mv_gpu.tflite;1:sub_7
multi_person_mobilenet_v1_075_float.tflite;1:sub_2
ide_label_base.tflite;1:input
ide_label_retrained.tflite;1:input_1
ml_ei_headpose.tflite;1:input_1
ml_ei_landmark.tflite;1:input_image
mnist.tflite;1:conv2d_input
mobilenet.tflite;1:conv2d_input
resnet.tflite;1:input_1
scan_hms_angle1.tflite;1:normalized_input_image_tensor
scan_hms_detect.tflite;1:normalized_input_image_tensor
hiai_latin_ocr.tflite;1:input_0
hiai_latin_ocr_1.tflite;1:input_0
ml_ocr_jk.tflite;1:input_0
nasnet_mobile.tflite;1:input
nasnet_large.tflite;1:input
model_emotions_0727_nosoftmax.tflite;1:input
inception_resnet_v2.tflite;1:input
ml_ocr_latin.tflite;1:input_0
hiai_PoseEstimation_Pcm.tflite;1:image
hiai_ssd_mobilenetv2_object.tflite;1:image_tensor
hiai_cv_focusShootOCRModel_02.tflite;1:input_0
hiai_cv_poseEstimation.tflite;1:Image
inception_v4.tflite;1:input
mtk_model_normalize_object_scene_ps_20200519_f16.tflite;1:input_0
mtk_age_gender_fp16.tflite;1:img
mtk_model_face_dress_fp16.tflite;1:img
mtk_AADB_HADB_MBV2_model_f16.tflite;1:input_0
mtk_AADB_HADB_MBV3_model_f16.tflite;1:input_0
mtk_model_emotions_0725_fp16.tflite;1:input
mtk_face_features_v1_fp16.tflite;1:input
siteAI_digcom_AI_ECN.tflite;1:input_expansion
siteAI_digcom_g2v_keras.tflite;1:conv2d_1_input
siteAI_trans_nonlinear.tflite;1:features_placeholder
siteAI_trans_tcpclassify.tflite;1:conv2d_1_input
siteAI_wireless_depress_w.tflite;1:x-input
siteAI_wireless_restore_w.tflite;1:x-input
magenta_arbitrary-image-stylization-v1-256_fp16_prediction_1.tflite;1:style_image
ml_object_detect.tflite;1:input/input_data
ml_object_detect_1.tflite;1:input/input_data
hiai_cpu_face_emotion.tflite;1:input_0
hiai_cpu_face_gazing.tflite;1:input_0
hiai_cpu_face_headpose.tflite;1:input_0
hiai_humanDetection.tflite;1:normalized_input_image_tensor
hiai_cv_focusShootOCRModel_08.tflite;1:input
ml_face_openclose.tflite;1:input
hiai_face_model_npu.tflite;1:input_0
hiai_ctpn_feature_map.tflite;1:input_image
hiai_cv_labelDetectorModel_v2.tflite;1:input_0
hiai_cv_labelDetectorModel_v4.tflite;1:input_0
hiai_dress_detect.tflite;1:data
hiai_cv_saliencyDetectorModel.tflite;1:image_tensor
hiai_frozen_inference_graph.tflite;1:image_tensor
hiai_ghostnet.tflite;1:input
hiai_iMaxDN_RGB.tflite;1:input
hiai_iMaxSR_RGB.tflite;1:input
hiai_label_and_video.tflite;1:input_0
hiai_lm_inference_graph.tflite;1:image_tensor
efficientnet_lite0_fp32_2.tflite;1:images
mnasnet_0.50_224_1_metadata_1.tflite;1:input
lite-model_on_device_vision_classifier_popular_us_products_V1_1.tflite;1:uint8_image_input
lite-model_on_device_vision_classifier_popular_wine_V1_1.tflite;1:uint8_image_input
posenet_mobilenet_float_075_1_default_1.tflite;1:sub_2
deeplabv3_1_default_1.tflite;1:sub_7
lite-model_deeplabv3-mobilenetv2_dm05-float16_1_default_1.tflite;1:sub_7
lite-model_deeplabv3-mobilenetv2-float16_1_default_1.tflite;1:sub_7
lite-model_east-text-detector_fp16_1.tflite;1:input_images
lite-model_cartoongan_fp16_1.tflite;1:input_photo
lite-model_arbitrary-image-stylization-inceptionv3_fp16_predict_1.tflite;1:style_image
gts_detect_5k_tf115.tflite;1:normalized_input_image_tensor
mtk_new_detect.tflite;1:input
mtk_model_emotions_0727_nosoftmax.tflite;1:input
mtk_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite;1:input_0
mtk_276landmark_0913.tflite;1:input
mtk_face_recognition.tflite;1:input
mtk_convert_model.tflite;1:data
smartreply.tflite;1:input_sentence
mindspore_text_classification_tflite.tflite;1:base_input
# ml_location.tflite
ml_text_correction.tflite;1:hed_input
ml_pic_shopping.tflite;1:images
ml_vision_guide_detection3_pb2tflite.tflite;1:input/input_data
ml_vision_guide_detection1_pb2tflite.tflite;1:input/input_data
ml_pic_shopping_pb2tflite.tflite;1:images
ml_ocr_jk_pb2tflite.tflite;1:input_0
ml_ocr_latin_pb2tflite.tflite;1:input_0
scan_hms_angle_pb2tflite.tflite;1:normalized_input_image_tensor
scan_hms_detect_pb2tflite.tflite;1:normalized_input_image_tensor
ml_location.tflite;1:inputs
ml_face_openclose_tflite.tflite;1:input
ml_object_detect_pb2tflite.tflite;1:input/input_data
Q_AADB_HADB_MBV2_model.tflite;1:input_0
Q_convert.tflite;1:input
Q_crnn_ori_75w_slim_norm_pb2tflite.tflite;1:input_0
Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite;1:input_0
Q_crnn_screen_slim400w_more_20w_pb2tflite.tflite;1:input_0
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid_tflite.tflite;1:input
Q_focusocr_cn_recog.tflite;1:input_0
Q_focusocr_jk_recog.tflite;1:input_0
Q_inception-249970-672-11-16_pb2tflite.tflite;1:input
Q_language_model_hrmini_Q4_b4_17w.tflite;1:input_0
Q_object_scene.tflite;1:input_0
ml_ei_landmark_pb2tflite.tflite;1:input_image
unet_mbv2_05_104pts.tflite;1:input
hiai_AADB_HADB_MBV2_model_f16.tflite;1:input_0
hiai_AADB_HADB_MBV2_model_fp32.tflite;1:input_0
hiai_detect_curve_model_float32.tflite;1:input
hiai_detectmodel_06_23_960_480_1180700.tflite;1:input
hiai_detectmodel_desnet_256_128_64_32.tflite;1:input
lite-model_aiy_vision_classifier_food_V1_1.tflite;1:input
lite-model_disease-classification_1.tflite;1:mobilenetv2_1_00_224_input
lite-model_models_mushroom-identification_v1_1.tflite;1:input
smartreply_1_default_1.tflite;1:input_sentence
text_classification.tflite;1:embedding_input
Q_detect_fpn_add_inception-1448650.tflite;1:input
Q_hand_0812_pb2tflite.tflite;1:input
Q888_age_gender_orderd.tflite;1:input
Q888_face_dress_mv3y.tflite;1:input
Q888_HADB_AADB_MBV2_model_fp32.tflite;1:input_0
# same model as mtk_landmark.tflite, bloom_landmark.tflite, Q_landmark.tflite
Q888_landmark.tflite;1:img
# same model as mtk_pose.tflite, Q_pose.tflite
Q888_pose.tflite;1:input
Q888_lapa158_unet_0924.tflite;1:input
# same model as mtk_isface.tflite, bloom_isface.tflite
Q888_isface.tflite;1:data
Q888_new_detect.tflite;1:input
Q888_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite;1:input_0
Q888_face_emo_dress_mv3_orderd.tflite;1:img
Q_iMaxDN_RGB_385_p_RGB_RGB_pb2tflite.tflite;1:images
Q_iMaxSR_RGB_385_p_pb2tflite.tflite;1:images
bloom_new_detect.tflite;1:input
bloom_model_age_gender.tflite;1:input
hiai_object_detect_814.tflite;1:normalized_input_image_tensor
hiai_object_tflite_graph_8bit.tflite;1:normalized_input_image_tensor
lma_tsec_shallow_channels16_ds2.1.1_model-best-f1.tflite;1:inputs
lite-model_arbitrary-image-stylization-inceptionv3_fp16_transfer_1.tflite;2:content_image,Conv/BiasAdd
magenta_arbitrary-image-stylization-v1-256_fp16_transfer_1.tflite;2:content_image,mobilenet_conv/Conv/BiasAdd
albert_lite_base_squadv1_1.tflite;3:input_ids,input_mask,segment_ids
mobilebert_1_default_1.tflite;3:input_ids,input_mask,segment_ids
ml_video_edit_img_segment_adaptise_pb2tflite.tflite;2:backbone_features2,w
ml_video_edit_video_segment_gauss_adaptis_part2_pb2tflite.tflite;2:backbone_features2,w
hdc_tb_cn_neg.tflite;3:input_ids,input_mask,segment_ids 0.5
hiai_cv_labelDetectorModel_v3.tflite;2:input_0,input_1
ml_tacotron_decoder_step_stf.tflite;9:previous_output,attention,h_0,c_0,h_1,c_1,kappa,encoder_outputs,time;1,80:1,256:1,1024:1,1024:1,1024:1,1024:1,8:1,1,256:1
ml_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm/add,batch_normalization_1/batchnorm/add;1,64,64,3:16:16
ml_ei_headpose_pb2tflite.tflite;3:input_1,batch_normalization_8/batchnorm_1/add,batch_normalization_1/batchnorm_1/add;1,64,64,3:16:16
lite-model_albert_lite_base_squadv1_metadata_1.tflite;3:input_ids,input_mask,segment_ids
lite-model_mobilebert_1_metadata_1.tflite;3:input_ids,input_mask,segment_ids
hiai_vad.tflite;2:input,input_cache
add_uint8.tflite;2:input0,input1
coco_ssd_mobilenet_v1_1.0.tflite
hiai_asr_last_e1_cpu_fast_wavenet_batch1_frame1_one_cache_fp32.tflite;2
hiai_asr_ctc.tflite;2
# weight quant model
tt_raw_h4800_mel80_ms_fe001_ex_20210506_encoder.tflite;25;1,15,80:1,15,80:1,15,80:1,15,80:1,15,80:1,15,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,31,80:1,640 8.5
# weight quant model
tt_raw_h4800_mel80_ms_fe001_ex_20210506_joint_decoder.tflite;14;4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:4,7,64:1,640:4 10.5
