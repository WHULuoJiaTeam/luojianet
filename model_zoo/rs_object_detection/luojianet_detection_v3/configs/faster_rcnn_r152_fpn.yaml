# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
# ==============================================================================
# model arts settings
enable_modelarts: False
data_url: ""
train_url: ""
checkpoint_url: ""
data_path: "/cache/data"
output_path: "/cache/output_dir/debug/"
load_path: "/cache/checkpoint_path"
enable_profiling: False
modelarts_dataset_unzip_name: 'cocodataset'
need_modelarts_dataset_unzip: False # True
img_path: ''
result_path: ''

# ==============================================================================
# Training options
device_target: GPU # Ascend
dataset: "coco"
device_id: 3  # 0,1
device_num: 1  # 2
rank_id: 0
run_distribute: False # True
pre_trained: './pretrained_models/resnet152.ckpt'
coco_root: "/luojiaNet/model_zoo/rs_object_detection/examples/mini_dataset/"
train_data_type: "train"
val_data_type: "train"
instance_set: "{}.json"
coco_classes: ['background', 'ap',]
num_classes: 2

# enable mask branch
mask_on: False

# LR
base_lr: 0.02
warmup_step: 500
warmup_ratio: 0.0625

# train
batch_size: 2
loss_scale: 256
momentum: 0.91
weight_decay: 0.0001 # 1e-4
epoch_size: 50
save_checkpoint: True
save_checkpoint_epochs: 5
keep_checkpoint_max: 7
save_checkpoint_path: "./output_dir/faster_rcnn_multi"
# pretrain_epoch_size: 0

# ==============================================================================
# model settings
img_width: 1024
img_height: 1024

keep_ratio: True
flip_ratio: 0.5

enable_ms: True
multi_scales: [[1024,1024], [1280,1280], [896, 896]]
# (w, h)  [1536, 1536] [1024,1024], [1280,1280], [896, 896]

max_instance_count: 128

# anchor
anchor_scales: [8]
anchor_ratios: [0.5, 1.0, 2.0]
anchor_strides: [4, 8, 16, 32, 64]
num_anchors: 3

# resnet
resnet_block: [3, 8, 36, 3]  # [3, 4, 6, 3]
resnet_in_channels: [64, 256, 512, 1024]
resnet_out_channels: [256, 512, 1024, 2048]

# fpn
fpn_in_channels: [256, 512, 1024, 2048]
fpn_out_channels: 256
fpn_num_outs: 5

# rpn
rpn_in_channels: 256
rpn_feat_channels: 256
rpn_loss_cls_weight: 1.0
rpn_loss_reg_weight: 1.0
rpn_cls_out_channels: 1
rpn_target_means: [0., 0., 0., 0.]
rpn_target_stds: [1.0, 1.0, 1.0, 1.0]

# bbox_assign_sampler
neg_iou_thr: 0.3
pos_iou_thr: 0.7
min_pos_iou: 0.3
num_gts: 128
num_expected_neg: 256
num_expected_pos: 128

# proposal
activate_num_classes: 2
use_sigmoid_cls: True

# roi_align
roi_layer: {type: 'RoIAlign', out_size: 7, sample_num: 2}
roi_align_out_channels: 256
roi_align_featmap_strides: [4, 8, 16, 32]
roi_align_finest_scale: 56
roi_sample_num: 640

# bbox_assign_sampler_stage2
neg_iou_thr_stage2: 0.5
pos_iou_thr_stage2: 0.5
min_pos_iou_stage2: 0.5
num_bboxes_stage2: 2000
num_expected_pos_stage2: 128
num_expected_neg_stage2: 512
num_expected_total_stage2: 512

# rcnn
rcnn_num_layers: 2
rcnn_in_channels: 256
rcnn_fc_out_channels: 1024
rcnn_loss_cls_weight: 1
rcnn_loss_reg_weight: 1
rcnn_target_means: [0., 0., 0., 0.]
rcnn_target_stds: [0.1, 0.1, 0.2, 0.2]

# train proposal
rpn_proposal_nms_across_levels: False
rpn_proposal_nms_pre: 2000
rpn_proposal_nms_post: 2000
rpn_proposal_max_num: 2000
rpn_proposal_nms_thr: 0.7
rpn_proposal_min_bbox_size: 0

# test proposal
rpn_nms_across_levels: False
rpn_nms_pre: 1000
rpn_nms_post: 1000
rpn_max_num: 1000
rpn_nms_thr: 0.7
rpn_min_bbox_min_size: 0
test_score_thr: 0.05
test_iou_thr: 0.5
test_max_per_img: 100
test_batch_size: 1

rpn_head_use_sigmoid: True
rpn_head_weight: 1.0

# ==============================================================================
# eval settings
eval_save_dir: './output_dir/eval_result/'
ann_file: "./examples/mini_dataset/train.json"
eval_checkpoint_path: './pretrained_models/faster_rcnn-30_2253.ckpt'

# ==============================================================================
# inference settings
inference_checkpoint_path: './pretrained_models/faster_rcnn-30_2253.ckpt'
inference_save_dir: './output_dir/inference_results/'
inference_img_dir: './examples/inference_images/'

only_create_dataset: False
do_train: True      
do_eval: False
# ==============================================================================
# fasterrcnn export
file_name: "fasterrcnn"
file_format: "AIR"
ckpt_file: '/cache/train/fasterrcnn/faster_rcnn-12_7393.ckpt'

## other
# learning_rate: 0.02
# buffer_size: 1000
# save_checkpoint_steps: 1562
# sink_size: -1
# dataset_sink_mode: False
# lr: 0.01

---
# Config description for each option
enable_modelarts: 'Whether training on modelarts, default: False'
data_url: 'Dataset url for obs'
train_url: 'Training output url for obs'
data_path: 'Dataset path for local'
output_path: 'Training output path for local'
ann_file: 'Ann file, default is val.json.'

device_target: 'Target device type' 
enable_profiling: 'Whether enable profiling while training, default: False'
only_create_dataset: 'If set it true, only create Mindrecord, default is false.'
run_distribute: 'Run distribute, default is false.'
do_train: 'Do train or not, default is true.'
do_eval: 'Do eval or not, default is false.'
dataset: 'Dataset, default is coco.'
pre_trained: 'Pretrain file path.'
device_id: 'Device id, default is 0.'
device_num: 'Use device nums, default is 1.'
rank_id: 'Rank id, default is 0.'
file_format: 'file format' 
img_path: "image file path."
result_path: "result file path."

---
device_target: ['Ascend', 'GPU', 'CPU']
file_format: ["AIR", "ONNX", "MINDIR"]
