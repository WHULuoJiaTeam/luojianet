# -*- coding: utf-8 -*-
"""Inference

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/Inference.ipynb

# PyTorch Metric Learning
See the documentation [here](https://kevinmusgrave.github.io/pytorch-metric-learning/)

## Install the packages
!pip install pytorch-metric-learning
!pip install -q faiss-gpu
!git clone https://github.com/akamaster/pytorch_resnet_cifar10
"""
"""## Import the packages"""
from attrdict import AttrDict
import yaml

from src.luojianet_metric_learning.utils.inference import MatchFinder, InferenceModel
from src.luojianet_metric_learning.distances import CosineSimilarity
from src.luojianet_metric_learning.utils import common_functions as c_f

import luojianet_ms.ops as P
from luojianet_ms import set_seed, context

from src.luojianet_ml_tool.dataset import *
from src.luojianet_ml_tool.model import *


def get_model(
        cfg_path=r'./configs/ml_standard.yaml',
        checkpoint_path= r"./output_dir/ml_mini_dataset/gt_det_12-10_5.ckpt",
        is_training=False,
    ):

    # get config file
    with open(cfg_path, 'r') as f:
        cfg = AttrDict(yaml.load(f, Loader=yaml.FullLoader))

    # load trainset
    trainset = DatasetGenerator(cfg, test_mode=False)
    # train labels to indice
    labels_to_indices = c_f.get_labels_to_indices(trainset.targets)
    name_list = trainset.names
    label_list = trainset.targets

    # load pretrained model
    model = ResNet152_ml(cfg, num_class=128)
    model.set_train(False)
    checkpoint = load_checkpoint(checkpoint_path)  # ml-60_120.ckpt
    load_param_into_net(model, checkpoint)
    model.linear = c_f.Identity()
    print("Finish model loading...")

    """## Create the InferenceModel wrapper"""
    match_finder = MatchFinder(distance=CosineSimilarity(), threshold=0.95)
    inference_model = InferenceModel(model, match_finder=match_finder, batch_size=64)

    # create faiss index
    resize_h = cfg.DATA.AUG.resize_h
    resize_w = cfg.DATA.AUG.resize_w
    mean = tuple(x / 255.0 for x in cfg.DATA.AUG.mean)
    std = tuple(x for x in cfg.DATA.AUG.std)

    resize_ops = c_vision.Resize((resize_h, resize_w))
    normalize_ops = c_vision.Normalize(mean=mean, std=std)

    train_vector_list = [c_vision.HWC2CHW()(normalize_ops(resize_ops(trainset[i][0]))) for i in range(len(trainset))]

    train_vectors = P.cast(luojianet_ms.Tensor.from_numpy(np.stack(train_vector_list, axis=0)), luojianet_ms.float32)
    inference_model.train_indexer(train_vectors, emb_dim=128)

    return cfg, inference_model, train_vectors, name_list, label_list, labels_to_indices


def preprocess_fn(cfg, image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, cfg.DATA.re_size, cv2.INTER_LINEAR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img / 255.0  # if get image directly from DatasetGenerator object

    resize_h = cfg.DATA.AUG.resize_h
    resize_w = cfg.DATA.AUG.resize_w

    mean = tuple(x / 255.0 for x in cfg.DATA.AUG.mean)
    std = tuple(x for x in cfg.DATA.AUG.std)

    img = c_vision.Resize((resize_h, resize_w))(img)
    img = c_vision.Normalize(mean=mean, std=std)(img)
    img = c_vision.HWC2CHW()(img)

    img = luojianet_ms.Tensor.from_numpy(img)
    img = P.expand_dims(img, 0)

    return img


def image2tensor(config_ml, img):
    img = cv2.resize(img, config_ml.DATA.re_size, cv2.INTER_LINEAR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img / 255.0  # if get image directly from DatasetGenerator object

    resize_h = config_ml.DATA.AUG.resize_h
    resize_w = config_ml.DATA.AUG.resize_w

    mean = tuple(x / 255.0 for x in config_ml.DATA.AUG.mean)
    std = tuple(x for x in config_ml.DATA.AUG.std)

    img = c_vision.Resize((resize_h, resize_w))(img)
    img = c_vision.Normalize(mean=mean, std=std)(img)
    img = c_vision.HWC2CHW()(img)

    img = luojianet_ms.Tensor.from_numpy(img)
    img = P.expand_dims(img, 0)

    return img


def ml_inference(ml_cfg, infer_img, inference_model, train_vectors, name_list, label_list, rank_k=5):
    """## Get nearest neighbors of a query"""
    cls_num = int(ml_cfg.DATA.cls_num)
    tmp_count = {}
    for i in range(cls_num):
        tmp_count[i] = 0

    infer_img = image2tensor(ml_cfg, infer_img)
    # get nearest image
    indices, distances = inference_model.get_nearest_neighbors(infer_img, k=rank_k)
    nearest_labels = np.array(label_list)[indices].reshape(-1)

    nearest_imgs = train_vectors.asnumpy()[indices]
    nearest_names = np.array(name_list)[indices].reshape(-1)
    # print(" ** {} nearest images".format(rank_k))
    for idx, alabel in enumerate(nearest_labels):
        # print('\t  {} ====> {};'.format(idx, nearest_names[idx]))
        if alabel in tmp_count:
            tmp_count[alabel] += 1
        else:
            raise Exception('Wrong classification name!!!')

    max_cls = max(tmp_count.values())
    pred = list(tmp_count.keys())[list(tmp_count.values()).index(max_cls)]

    return pred


if __name__ == "__main__":
    """set random seed"""
    set_seed(1)

    """set gpu devices"""
    context.set_context(mode=context.PYNATIVE_MODE, device_target="GPU", device_id=int(os.getenv('DEVICE_ID', '0')))

    # get config file
    cfg_path = r'../../configs/ml_standard.yaml'
    cfg, inference_model, train_vectors, name_list, label_list, labels_to_indices = get_model(
        cfg_path=cfg_path, checkpoint_path=r"../../output_dir/ml_models/gt_det_12-300_54.ckpt")

    # load test image
    test_img_path = r'../../examples/ml_mini_dataset/100_B_10.png'  # 100_B_10.png
    test_img = preprocess_fn(cfg, test_img_path)

    pred = ml_inference(test_img, inference_model, train_vectors, name_list, label_list, rank_k=3)

    print('Predicted Result:\n\t{} --- {}'.format(test_img_path, pred))

